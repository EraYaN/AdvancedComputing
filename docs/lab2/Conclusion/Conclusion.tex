%!TEX program=xelatex
%!TEX spellcheck=en_US
\documentclass[final]{report}
\input{../../.library/preamble.tex}
\input{../../.library/style.tex}
\addbibresource{../../.library/bibliography.bib}
\begin{document}
\chapter{Conclusion}

Wrapping up the results, one can conclude that each processing step is being sped up by running it on a GPU.
However in many cases one cannot simply copy the CPU kernel code to the GPU, a lot of focus needs to be put in using the different memory layers.
In order to not only get a fast executing kernel, but also a fast executing program.

\cref{fig:total-cuda-speedup} and \cref{fig:kernel-cuda-speedup} illustrate the overall and kernel speedups per kernel, the naive histogram implementation has been left out.

\begin{figure}[H]
\centering
    \includegraphics[width=\linewidth]{resources/total-cuda-speedup-shared.pdf}
    \caption{The total speedup of the CUDA kernels.}
    \label{fig:total-cuda-speedup}
\end{figure}

\begin{figure}[H]
\centering
    \includegraphics[width=\linewidth]{resources/kernel-cuda-speedup-shared.pdf}
    \caption{The kernel speedup of the CUDA kernels.}
    \label{fig:kernel-cuda-speedup}
\end{figure}

The smoothing kernel saw the biggest improvement of all, even when using the naive CUDA implementation.
Regardless of the implementation, the filter has the largest sequential running time, allowing the GPU to have the biggest impact when executing everything in a parallel manner.
A speedup as high as 196384.8 has been achieved with the smoothing kernel on the largest image (image09).
Since the relatively slow data transfer between the CPU and GPU, the overall speedup became 44.6 in the end.

The grayscale kernel saw the smallest improvement of all, this has to do a lot with the explanation above.
The GPU starts outperforming the CPU once it is able to execute a lot of computations in parallel.
This is also the case for the grayscale kernel, \cref{fig:kernel-cuda-speedup} shows that the speedup in the kernel is between 100 and 2500 depending on the image size.
However, the reason that grayscale sees the smalles improvement is due to the relative short sequential running time of the kernel.
The smaller this running time, the smaller the impact an improved kernel speed will have on the overall outcome; the lower overall speedup is a result of this.

When one looks at the improvement in kernel times, it is clear that the bigger the image the bigger the improvement in execution time.
However, when one compares this performance to the overall speedup the picture is very different.
The overall speedup is roughly the same for each images.
This indicates that even though the kernel itself has a much more noticeable performance increase for larger data sets, the speedup is compensated by the larger dataset that needs to be copied to the GPU.
Therefore the overall speedup is the same for big and small images.

\end{document}